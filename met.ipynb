{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bdd913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
      "0   25         130           80  15.0      98.0         86  high risk\n",
      "1   35         140           90  13.0      98.0         70  high risk\n",
      "2   29          90           70   8.0     100.0         80  high risk\n",
      "3   30         140           85   7.0      98.0         70  high risk\n",
      "4   35         120           60   6.1      98.0         76   low risk\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Maternal Health Risk Data Set.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bed7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Models...\n",
      "\n",
      "Logistic Regression Accuracy: 0.6207\n",
      "Decision Tree Accuracy: 0.8177\n",
      "Gradient Boosting Accuracy: 0.7685\n",
      "Support Vector Machine Accuracy: 0.7241\n",
      "K-Nearest Neighbors Accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fortransferee\\mlproject6-p\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "\n",
      "e:\\fortransferee\\mlproject6-p\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.6847\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121\n",
      "[LightGBM] [Info] Number of data points in the train set: 811, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.318371\n",
      "[LightGBM] [Info] Start training from score -0.914443\n",
      "[LightGBM] [Info] Start training from score -1.103557\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 0.8424\n",
      "CatBoost Accuracy: 0.8571\n",
      "\n",
      "Performing Hyperparameter Tuning...\n",
      "Tuned Random Forest Accuracy: 0.8571\n",
      "Best Params: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fortransferee\\mlproject6-p\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning:\n",
      "\n",
      "[18:29:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Accuracy: 0.8571\n",
      "Best Params: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 7, 'classifier__n_estimators': 300}\n",
      "\n",
      "✅ Overall Best Model: CatBoost with Accuracy: 0.8571428571428571\n",
      "\n",
      "Label Encoding of RiskLevel: {'high risk': np.int64(0), 'low risk': np.int64(1), 'mid risk': np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (path for Kaggle environment)\n",
    "df = pd.read_csv(\"E:/fortransferee/mlproject6-p/Maternal Health Risk Data Set.csv\")\n",
    "# Encode target (RiskLevel)\n",
    "label_encoder = LabelEncoder()\n",
    "df['RiskLevel'] = label_encoder.fit_transform(df['RiskLevel'])\n",
    "\n",
    "# Features & target\n",
    "X = df.drop(columns=['RiskLevel'])\n",
    "y = df['RiskLevel']\n",
    "\n",
    "# Detect categorical & numerical columns\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Preprocessing\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, num_cols),\n",
    "    ('cat', categorical_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# ==========================\n",
    "# 🔹 Candidate Models (with Tuned Versions)\n",
    "# ==========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=500),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids for tuning\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# 🔹 Train/Test Split\n",
    "# ==========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# 🔹 Evaluate Models with or without Tuning\n",
    "# ==========================\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "\n",
    "print(\"Evaluating Models...\\n\")\n",
    "\n",
    "# Evaluate standard models\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = name\n",
    "\n",
    "# Evaluate tuned models\n",
    "print(\"\\nPerforming Hyperparameter Tuning...\")\n",
    "\n",
    "# Tuned Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "rf_grid = GridSearchCV(rf_pipeline, rf_param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_pred = rf_grid.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "print(f\"Tuned Random Forest Accuracy: {rf_acc:.4f}\")\n",
    "print(\"Best Params:\", rf_grid.best_params_)\n",
    "if rf_acc > best_acc:\n",
    "    best_acc = rf_acc\n",
    "    best_model = \"Tuned Random Forest\"\n",
    "\n",
    "# Tuned XGBoost\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42))\n",
    "])\n",
    "xgb_grid = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "xgb_pred = xgb_grid.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "print(f\"Tuned XGBoost Accuracy: {xgb_acc:.4f}\")\n",
    "print(\"Best Params:\", xgb_grid.best_params_)\n",
    "if xgb_acc > best_acc:\n",
    "    best_acc = xgb_acc\n",
    "    best_model = \"Tuned XGBoost\"\n",
    "\n",
    "print(\"\\n✅ Overall Best Model:\", best_model, \"with Accuracy:\", best_acc)\n",
    "\n",
    "# Show label encoding mapping for clarity\n",
    "print(\"\\nLabel Encoding of RiskLevel:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7de721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CatBoost model saved as maternal_health_catboost_best.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Build pipeline with preprocessing + fitted CatBoost model\n",
    "catboost_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', models[\"CatBoost\"])\n",
    "])\n",
    "\n",
    "# Fit pipeline on training data\n",
    "catboost_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save as pickle file\n",
    "pickle_filename = \"maternal_health_catboost_best.pkl\"\n",
    "with open(pickle_filename, \"wb\") as f:\n",
    "    pickle.dump(catboost_pipeline, f)\n",
    "\n",
    "print(f\"✅ CatBoost model saved as {pickle_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "\n",
      "Number of 'high risk' samples in the dataset: 336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"Maternal Health Risk Data Set.csv\")\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Maternal Health Risk Data Set.csv' not found. Please ensure the file is in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "high_risk_samples = df[df['RiskLevel'] == 'mid risk']\n",
    "\n",
    "# Get the count of these samples\n",
    "number_of_high_risk_samples = len(high_risk_samples)\n",
    "\n",
    "print(f\"\\nNumber of 'high risk' samples in the dataset: {number_of_high_risk_samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe359488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Models...\n",
      "\n",
      "Logistic Regression Accuracy: 0.6207\n",
      "Decision Tree Accuracy: 0.8424\n",
      "Gradient Boosting Accuracy: 0.7685\n",
      "Support Vector Machine Accuracy: 0.7241\n",
      "K-Nearest Neighbors Accuracy: 0.6700\n",
      "Neural Network Accuracy: 0.7044\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121\n",
      "[LightGBM] [Info] Number of data points in the train set: 811, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.318371\n",
      "[LightGBM] [Info] Start training from score -0.914443\n",
      "[LightGBM] [Info] Start training from score -1.103557\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 0.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fortransferee\\mlproject6-p\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Accuracy: 0.8571\n",
      "\n",
      "Performing Hyperparameter Tuning...\n",
      "Tuned Random Forest Accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\fortransferee\\mlproject6-p\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Accuracy: 0.8571\n",
      "\n",
      "✅ Overall Best Model: CatBoost with Accuracy: 0.8571\n",
      "✅ Best model saved to best_model.pkl\n",
      "\n",
      "--- Making Predictions with the Best Model ---\n",
      "\n",
      "--- Prediction for: Low Risk Example ---\n",
      "Input Data:\n",
      "            name  Age  SystolicBP  DiastolicBP  BS  BodyTemp  HeartRate\n",
      "Low Risk Example 25.0       120.0         80.0 6.0      98.6       80.0\n",
      "Predicted Risk Level: low risk\n",
      "\n",
      "--- Prediction for: Mid Risk Example ---\n",
      "Input Data:\n",
      "            name  Age  SystolicBP  DiastolicBP  BS  BodyTemp  HeartRate\n",
      "Mid Risk Example 35.0       130.0         85.0 8.0      99.5       95.0\n",
      "Predicted Risk Level: high risk\n",
      "\n",
      "--- Prediction for: High Risk Example ---\n",
      "Input Data:\n",
      "             name  Age  SystolicBP  DiastolicBP   BS  BodyTemp  HeartRate\n",
      "High Risk Example 40.0       145.0         95.0 12.0     100.2      110.0\n",
      "Predicted Risk Level: high risk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palak Mathur\\AppData\\Local\\Temp\\ipykernel_9968\\4148477223.py:199: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prediction = int(prediction_array[0])\n",
      "C:\\Users\\Palak Mathur\\AppData\\Local\\Temp\\ipykernel_9968\\4148477223.py:199: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prediction = int(prediction_array[0])\n",
      "C:\\Users\\Palak Mathur\\AppData\\Local\\Temp\\ipykernel_9968\\4148477223.py:199: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prediction = int(prediction_array[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Maternal Health Risk Data Set.csv\")\n",
    "# Encode target (RiskLevel)\n",
    "label_encoder = LabelEncoder()\n",
    "df['RiskLevel'] = label_encoder.fit_transform(df['RiskLevel'])\n",
    "\n",
    "# Features & target\n",
    "X = df.drop(columns=['RiskLevel'])\n",
    "y = df['RiskLevel']\n",
    "\n",
    "# Detect categorical & numerical columns\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, num_cols),\n",
    "    ('cat', categorical_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=500),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids for tuning\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "xgb_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "best_model_name = None\n",
    "best_acc = 0\n",
    "best_model_object = None\n",
    "\n",
    "print(\"Evaluating Models...\\n\")\n",
    "\n",
    "# Evaluate standard models\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model_name = name\n",
    "        best_model_object = pipeline\n",
    "\n",
    "# Evaluate tuned models\n",
    "print(\"\\nPerforming Hyperparameter Tuning...\")\n",
    "\n",
    "# Tuned Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "rf_grid = GridSearchCV(rf_pipeline, rf_param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_pred = rf_grid.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "print(f\"Tuned Random Forest Accuracy: {rf_acc:.4f}\")\n",
    "if rf_acc > best_acc:\n",
    "    best_acc = rf_acc\n",
    "    best_model_name = \"Tuned Random Forest\"\n",
    "    best_model_object = rf_grid\n",
    "\n",
    "# Tuned XGBoost\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42))\n",
    "])\n",
    "xgb_grid = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "xgb_pred = xgb_grid.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "print(f\"Tuned XGBoost Accuracy: {xgb_acc:.4f}\")\n",
    "if xgb_acc > best_acc:\n",
    "    best_acc = xgb_acc\n",
    "    best_model_name = \"Tuned XGBoost\"\n",
    "    best_model_object = xgb_grid\n",
    "\n",
    "print(f\"\\nOverall Best Model: {best_model_name} with Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "\n",
    "if best_model_object:\n",
    "    pickle_filename = \"best_model.pkl\"\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(best_model_object, file)\n",
    "    print(f\" Best model saved to {pickle_filename}\")\n",
    "else:\n",
    "    print(\" No best model found to save.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Making Predictions with the Best Model ---\")\n",
    "\n",
    "# Define manual input data examples\n",
    "data_examples = [\n",
    "    {\n",
    "        \"name\": \"Low Risk Example\",\n",
    "        'Age': [25.0],\n",
    "        'SystolicBP': [120.0],\n",
    "        'DiastolicBP': [80.0],\n",
    "        'BS': [6.0],\n",
    "        'BodyTemp': [98.6],\n",
    "        'HeartRate': [80.0]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Mid Risk Example\",\n",
    "        'Age': [35.0],\n",
    "        'SystolicBP': [130.0],\n",
    "        'DiastolicBP': [85.0],\n",
    "        'BS': [8.0],\n",
    "        'BodyTemp': [99.5],\n",
    "        'HeartRate': [95.0]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"High Risk Example\",\n",
    "        'Age': [40.0],\n",
    "        'SystolicBP': [145.0],\n",
    "        'DiastolicBP': [95.0],\n",
    "        'BS': [12.0],\n",
    "        'BodyTemp': [100.2],\n",
    "        'HeartRate': [110.0]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Map the numerical prediction back to the risk level string\n",
    "risk_map = {0: 'high risk', 1: 'low risk', 2: 'mid risk'}\n",
    "\n",
    "# Predict for each example using the best model\n",
    "for example in data_examples:\n",
    "    print(f\"\\n--- Prediction for: {example['name']} ---\")\n",
    "    \n",
    "    # Create a DataFrame from the manual input\n",
    "    input_df = pd.DataFrame(example)\n",
    "\n",
    "    # Use the best model pipeline to make a prediction\n",
    "    prediction_array = best_model_object.predict(input_df)\n",
    "    \n",
    "    # Extract the single integer value from the prediction array\n",
    "    prediction = int(prediction_array[0])\n",
    "\n",
    "    # Interpret and print the prediction\n",
    "    predicted_risk = risk_map.get(prediction, \"Unknown\")\n",
    "    print(f\"Input Data:\\n{input_df.to_string(index=False)}\")\n",
    "    print(f\"Predicted Risk Level: {predicted_risk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b2e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully from 'best_model.pkl'!\n",
      "\n",
      "--- Making a prediction for: Low Risk Example ---\n",
      "Input Data:\n",
      " Age  SystolicBP  DiastolicBP  BS  BodyTemp  HeartRate\n",
      "25.0       120.0         80.0 6.0      98.6       80.0\n",
      "Predicted Risk Level: low risk\n",
      "\n",
      "--- Making a prediction for: Mid Risk Example ---\n",
      "Input Data:\n",
      " Age  SystolicBP  DiastolicBP  BS  BodyTemp  HeartRate\n",
      "35.0       130.0         85.0 8.0      99.5       95.0\n",
      "Predicted Risk Level: high risk\n",
      "\n",
      "--- Making a prediction for: High Risk Example ---\n",
      "Input Data:\n",
      " Age  SystolicBP  DiastolicBP  BS  BodyTemp  HeartRate\n",
      "35.0       140.0        100.0 9.0      98.0       66.0\n",
      "Predicted Risk Level: high risk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palak Mathur\\AppData\\Local\\Temp\\ipykernel_9968\\2176904914.py:78: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prediction = int(prediction_array[0])\n",
      "C:\\Users\\Palak Mathur\\AppData\\Local\\Temp\\ipykernel_9968\\2176904914.py:78: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prediction = int(prediction_array[0])\n",
      "C:\\Users\\Palak Mathur\\AppData\\Local\\Temp\\ipykernel_9968\\2176904914.py:78: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  prediction = int(prediction_array[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# ==========================\n",
    "# 📌 Load the Best Model\n",
    "# ==========================\n",
    "# Ensure your 'best_model.pkl' file is in the same directory.\n",
    "try:\n",
    "    with open('best_model.pkl', 'rb') as file:\n",
    "        model_pipeline = pickle.load(file)\n",
    "    print(\" Model loaded successfully from 'best_model.pkl'!\")\n",
    "except FileNotFoundError:\n",
    "    print(\" Error: 'best_model.pkl' not found.\")\n",
    "    print(\"Please ensure the file is in the same directory and try again.\")\n",
    "    # Exit the script if the model file is not found\n",
    "    exit()\n",
    "\n",
    "# ==========================\n",
    "# 📌 Define Manual Input Data Examples\n",
    "# ==========================\n",
    "# A list of dictionaries, each representing a different patient profile.\n",
    "# The features are: Age, SystolicBP, DiastolicBP, BS, BodyTemp, HeartRate\n",
    "data_examples = [\n",
    "    {\n",
    "        \"name\": \"Low Risk Example\",\n",
    "        'Age': [25.0],\n",
    "        'SystolicBP': [120.0],\n",
    "        'DiastolicBP': [80.0],\n",
    "        'BS': [6.0],\n",
    "        'BodyTemp': [98.6],\n",
    "        'HeartRate': [80.0]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Mid Risk Example\",\n",
    "        'Age': [35.0],\n",
    "        'SystolicBP': [130.0],\n",
    "        'DiastolicBP': [85.0],\n",
    "        'BS': [8.0],\n",
    "        'BodyTemp': [99.5],\n",
    "        'HeartRate': [95.0]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"High Risk Example\",\n",
    "        'Age': [35.0],\n",
    "        'SystolicBP': [140.0],\n",
    "        'DiastolicBP': [100.0],\n",
    "        'BS': [9.0],\n",
    "        'BodyTemp': [98.0],\n",
    "        'HeartRate': [66.0]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Map the numerical prediction back to the risk level string.\n",
    "risk_map = {0: 'high risk', 1: 'low risk', 2: 'mid risk'}\n",
    "\n",
    "for example in data_examples:\n",
    "    print(f\"\\n--- Making a prediction for: {example['name']} ---\")\n",
    "    \n",
    "    # Create a DataFrame from the manual input.\n",
    "    input_df = pd.DataFrame({\n",
    "        'Age': example['Age'],\n",
    "        'SystolicBP': example['SystolicBP'],\n",
    "        'DiastolicBP': example['DiastolicBP'],\n",
    "        'BS': example['BS'],\n",
    "        'BodyTemp': example['BodyTemp'],\n",
    "        'HeartRate': example['HeartRate']\n",
    "    })\n",
    "\n",
    "    print(f\"Input Data:\\n{input_df.to_string(index=False)}\")\n",
    "\n",
    "    # Use the loaded model pipeline to make a prediction.\n",
    "    prediction_array = model_pipeline.predict(input_df)\n",
    "    \n",
    "    # Extract the single integer value from the prediction array.\n",
    "    prediction = int(prediction_array[0])\n",
    "\n",
    "    # Interpret the prediction using the risk map.\n",
    "    predicted_risk = risk_map.get(prediction, \"Unknown\")\n",
    "    print(f\"Predicted Risk Level: {predicted_risk}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
